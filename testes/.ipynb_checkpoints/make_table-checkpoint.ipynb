{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# metodo de tratar tabelas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "#\n",
    "# converter arquivo DOC para arquivo DOCX -> AINDA NÃO FUNCIONA\n",
    "#\n",
    "#\n",
    "\n",
    "# https://stackoverflow.com/questions/38468442/multiple-doc-to-docx-file-conversion-using-python\n",
    "from glob import glob\n",
    "import re\n",
    "import os\n",
    "import win32com.client as win32\n",
    "from win32com.client import constants\n",
    "\n",
    "# Create list of paths to .doc files\n",
    "paths = glob('C:\\\\path\\\\to\\\\doc\\\\files\\\\**\\\\*.doc', recursive=True)\n",
    "\n",
    "def save_as_docx(path):\n",
    "    # Opening MS Word\n",
    "    word = win32.gencache.EnsureDispatch('Word.Application')\n",
    "    doc = word.Documents.Open(path)\n",
    "    doc.Activate ()\n",
    "\n",
    "    # Rename path with .docx\n",
    "    new_file_abs = os.path.abspath(path)\n",
    "    new_file_abs = re.sub(r'\\.\\w+$', '.docx', new_file_abs)\n",
    "\n",
    "    # Save and Close\n",
    "    word.ActiveDocument.SaveAs(\n",
    "        new_file_abs, FileFormat=constants.wdFormatXMLDocument\n",
    "    )\n",
    "    doc.Close(False)\n",
    "\n",
    "for path in paths:\n",
    "    save_as_docx(files_array_19_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Existe esse diretório?  True\n",
      "Existe esse diretório?  True\n",
      "Quantidade de arquivos do word no diretório:  60\n",
      "Quantidade de arquivos do word no diretório:  61\n",
      "ID228354-CNI_ Estudo Mecanismo de Soluá∆o de Consulta Antecipada_vf+RevisaoGramatical.docx\n",
      "ID235502-Investimentos_Roadmap_BrasilUK_v5_Normalizado.docx\n",
      "ID232098-2019-09-16_30 CASOS_FINAL 20190820 (inglês).docx\n",
      "ID225392-Manual Ouvidoria do SESI SENAI REVISADO POR DANUZIA - NORMALIZADOv2 - 06.11.18.docx\n",
      "ID228307-Pesquisa Sindical 2018_Relatório_versão final.docx\n",
      "ID224325-Reuso_PE-normalizado_revisado_final.docx\n",
      "ID232211-Agendar for USA.docx\n",
      "ID230571-10 Chamada_20190619 - - (1).docx\n",
      "ID229536-Avanços da Gestão SESI-SENAI-IEL v10.docx\n",
      "ID231772-Versão preliminar I-2027 MPE-2.docx\n",
      "ID226842-20190115 Estudo_ApoioExportadorDefesaComercial_v08.docx\n",
      "ID231928-Investimentos_Tributação_Roadmap_BrasilEUA_20190328_Normalizado_06092019_123259.docx\n",
      "ID233550-2019-11-25_CNI Agências Reguladoras Subnacionais- v2 - normalização concluída.docx\n",
      "ID228603-Posicao Mercosul PPT Argentina_v11.docx\n",
      "ID228863-2019-03-25 _TratamentodaChinaComoEconomiadeMercado_NME_v04.docx\n",
      "ID231316-Mexico_InteressesOfensivos_201907_Normalizado_v02.docx\n",
      "ID229294 -Normatizado  Livro ESocial - empregado ajustado depois da DJ_revisado empresa externa.docx\n",
      "ID231829-2019-08-20 Estudo_CustosAeroportuarios_Relatorio_v15_normalizado.docx\n",
      "ID230908-2019-07-04 Alemanha_2019_v4.docx\n",
      "ID231210-2019-09-06 NR 12 - Comentarios ao novo texto geral. edição para diagramação.docx\n",
      "ID229323-Normatizado  Livro ESocial - empregado ajustado depois da DJ_revisado empresa externa.docx\n",
      "ID000003-Estudo temático_Impactos da revolução digital Unesco_Unificado_19ago2019.docx\n",
      "ID228837-Mercosul_Alteracao Tarifaria_201902_v09_Normalizado (1).docx\n",
      "ID228437-Recuperacao_Energetica_normalizado_revisado.docx\n",
      "ID230630-2019-06-24_Reuso PB_normalizada_V02.docx\n",
      "ID233405-2019-11-14 1128 Cartilha licenciamento ambiental_V9_normalizado_revisado_14112019_180959.docx\n",
      "ID233069-AgendaPara_MÇxico_2019.docx\n",
      "ID233474-Ecommerce_ResultadosConsulta_v06_Normalizado.docx\n",
      "ID000000-Manual de formatos - Oficial.docx\n",
      "ID231055-AgendaPara_EstadosUnidos_2019 (1).docx\n",
      "ID232596-CNI_DocumentodePosicao_Brexit_v11_Normalizado.docx\n",
      "ID225531-Versão Revisada e Normalizada_FINAL.docx\n",
      "ID230301-2019.06.05_reuso rj_V03.docx\n",
      "ID233269-19.11 Relatorio Executivo FINAL_Normalizado.docx\n",
      "ID228711-RELAToRIO SESI SENAI IEL 2018_PRELIMINAR_NORMALIZADO_2019.03.14.docx\n",
      "ID231931-2019-08-26 Posiá∆o CNI_Reforma da OMC_v06_20190808_normalizado.docx\n",
      "ID232943-CNI_FC_Estudo_FacilitacaoComercioMercosul_vlimpa_normalizada REVISADO_rp FINAL (2).docx\n",
      "ID231201-2019-07-23_30 CASOS_FINAL REVISADO NORMALIZAÇÃO.docx\n",
      "ID229345-OECD_CompatibilidadeSistemaBrasileiro_v08_Normalizado.docx\n",
      "ID230277-19.05 Estudo final Esp gás_Nornalizado_Rev J (2).docx\n",
      "ID231274-Versão Preliminar do Plano Estratégico_v10_enviado para Diret.docx\n",
      "ID229428-Doc de Política Industrial Revisado - 02-04-2019_02052019_145149.docx\n",
      "ID230874-Estudo_ProdutividadedasMultis_Normalizado.docx\n",
      "ID232396-FinanciamentoeGarantias_BenchmarkingInternacional_v08_Normalizado.docx\n",
      "ID232174-2019-08-23 AgendaPara_Japao_2019.docx\n",
      "ID231938-AgendaPara_Alemanha_2019_Mark.docx\n",
      "ID22703-FINAL_Agenda Jurídica da Indústria 2019 - STF (ÁBARIS)_31012019_145404.docx\n",
      "ID230059-CNI_ConselhosUsuarios_Completa_20190510_vnormalizada-revisada (1).docx\n",
      "ID225392-CNI_Atos Internacionais_201810_normalizado_final.docx\n",
      "ID231431-Re£so ES_nor_rev.docx\n",
      "ID224323-Reuso_CE-normalizado_revisado_final.docx\n",
      "ID233263-2019-11-05 Boas praticas de parceria_Versao consolidada3_para editoração.docx\n",
      "ID230385-Investimentos_ManualdeAcordosPrevidenci rio_v6_Normalizado.docx\n",
      "ID232625-Guia do Docente_Editorado.docx\n",
      "ID231890-Posicionamento sobre licenciamento ambiental VFinal.docx\n",
      "ID232393-Guia Avaliação última versão v 02_10_2019 _ Normalizado (1).docx\n",
      "ID231637-2019-08-09 CNI_CAM_Avancos&ImpactosParaBrasil_EstudoNormativoAduaneiro_20190718_v01r_limpa_ REVISADO.docx\n",
      "ID233072-2019-10-22 AgendaPara_Argentina_2019.docx\n",
      "ID232872-CNI_FC_GestaoRiscoOrgaosAnuentesComercioExterior_Estudo_vf.docx\n",
      "ID227130-2019-01-18_Guia de Financiamento Climático_vs final (2).docx\n",
      "ID235651-2020-06-16 AgendaPara_BRICS_2020_Normalizada (1).docx\n",
      "ID236123-Carta_presidente_20201002_MC Precificação de Carbono  e Competitividade da Indústria_v01_atualizada (1).docx\n",
      "ID235534-2020-06-02 AgendaPara_Japao_2020_Normalizada (3).docx\n",
      "ID235502-Investimentos_Roadmap_BrasilUK_v5_Normalizado.docx\n",
      "ID235665-Normas e Politicas de Uso_Revisado DJ_FINAL.docx\n",
      "ID233694-Relatório Diretoria Jurídica 2018-1 - Cópia (1).docx\n",
      "ID233896-2020-01-29 AII2020_Consolidação_V10.docx\n",
      "ID235810-AgendaPara_China_Normalizada (1).docx\n",
      "ID233899-Caderno de ações e resultados 2019 - Versão Editoração .docx\n",
      "ID235305-Mercosul_ImpactosJuridicosSaidaBrasil_RelatorioCompleto_202003_v03_Normalizado (1).docx\n",
      "ID233903-2020-05-02 Tradução Relatórios EUA e UE Distorções China_2020_v02 REVISADO_NORMALIZADO_sem comentários.docx\n",
      "ID235520-2020-05-25 AgendaPara_Alemanha_2020_Normalizada (1).docx\n",
      "ID235980-Educação Infantil  4 e 5  anos - Diagramar.docx\n",
      "ID235512-2020-06-05 OCDE_EstudoConvergênciaInstrumentosMeioAmbiente_v10_normalizado (1).docx\n",
      "ID233904-2020-03-06 Estudo CNI_ China  Subsídios chineses identificados em investigações sobre medidas compensatórias no mundo(459760.20) (003)_Normalizado.docx\n",
      "ID235513-2020-05-14 GUIA_PPN-Corrigido_Final_normalizado REVISADO-Comentado (1).docx\n",
      "ID235664-Governança de Dados_Revisado DJ_FINAL.docx\n",
      "ID235511-2020-05-29 AgendaParaEUA_2020_normalizado.docx\n",
      "ID235509-Investimentos_Estudo_Compatibilidade da cláusula de arbitragem com os ADTs celebrados pelo Brasil_Normalizado.docx\n",
      "ID235142-2020-03-30 0922 Bioeconomia e a Indústria Brasileira_30-03-2020_normalizado_vf.docx\n",
      "ID233900-Relatório Atividades 2019_SESI-SENAI-IEL_versão preliminar.docx\n",
      "ID233892-8- Templates.docx\n",
      "ID235382-2020-05-20-1 Manual de eventos.docx\n",
      "ID236105-2020-09-23 Estudo_NormasLegais_CNI_vers∆o_revisada_set2020 (1).docx\n",
      "ID233909-2020-03-11 publicacao_caminho_estrategico_economia_circular (ingl.)_normalizado.docx\n",
      "ID233867-06_12_2019_EFEITOS DA GESTÃO SOBRE A PRODUTIVIDADE - PARA PUBLICAÇÃO_Final_19122019_155125.docx\n",
      "ID233884-Agenda Jurídica STF 2020 (versão PRELIMINAR).docx\n",
      "ID235701-08-07-2020 2º GUIA - Tempo de Ensinar e Aprender Final - Validado e Revisado (1).docx\n",
      "ID235650-2020-06-05 AgendaPara_Argentina_2020_Normalizada (1).docx\n",
      "ID235353-2020-05-06 Estudo CNI _ Documento de POsição OMC sem Órgão de Apelação.docx\n",
      "ID235313-2020-05-05 2320 CNI - Estudo - Protocolo de Nagoya - normalizado_ 06_05.docx\n",
      "ID233885-1- Metodol Rec Did - rev.docx\n",
      "ID233893-Códigos_EstudoCNI_v10.docx\n",
      "ID233891-7- Guia Microlearning - rev.docx\n",
      "ID235700-2020-06-26 1º GUIA - TEMPO DE PLANEJAR - Validado REVISADO.docx\n",
      "ID235812-AgendaPara_India_Normalizada (2).docx\n",
      "ID233905-Proposta da Industria 2020-2022 2020_03_04.docx\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'group'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-808953bbf7db>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0mvar_19\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfileDir_19\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfiles_array_19\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m \u001b[0mvar_20\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfileDir_20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfiles_array_20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;31m#print(var)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/repositorios/Fluxo_Editorial/testes/get_file_word.py\u001b[0m in \u001b[0;36mget_info\u001b[0;34m(fileDir, files_array)\u001b[0m\n\u001b[1;32m     44\u001b[0m                 \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'(?<=\\<Pages\\>)(.*)(?=\\<\\/Pages\\>)'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpagina_xml_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m                     \u001b[0mpagina_xml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'group'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import get_file_word as gf\n",
    "import datetime\n",
    "import pandas as pd\n",
    "\n",
    "#setar variáveis onde estão arquivos\n",
    "fileExt = r\".docx\"\n",
    "fileExt2 = r\".doc\"\n",
    "fileDir_19 = r\"/Users/wpessoa/repositorios/NGE/words_2019/\"\n",
    "fileDir_20 = r\"/Users/wpessoa/repositorios/NGE/words_2020/\"\n",
    "\n",
    "\n",
    "fileDir_semNF = r\"/Users/wpessoa/repositorios/NGE/words_semNota/\"\n",
    "\n",
    "# verificar se existe o diretório\n",
    "print(\"Existe esse diretório? \",os.path.exists(fileDir_19)) \n",
    "print(\"Existe esse diretório? \",os.path.exists(fileDir_20)) \n",
    "\n",
    "\n",
    "#fileDir = r\"/Users/wpessoa/repositorios/Fluxo_Editorial/words/\"\n",
    "#fileDir= r'/Users/walnerpessoa/repositories/Fluxo_Editorial/words'\n",
    "files_array_19 = [_ for _ in os.listdir(fileDir_19) if _.endswith(fileExt)]\n",
    "#files_array_19_2 = [_ for _ in os.listdir(fileDir_19) if _.endswith(fileExt2)]\n",
    "#files_array_19=files_array_19_1+files_array_19_2\n",
    "\n",
    "\n",
    "files_array_20 = [_ for _ in os.listdir(fileDir_20) if _.endswith(fileExt)]\n",
    "#files_array_20_2 = [_ for _ in os.listdir(fileDir_20) if _.endswith(fileExt2)]\n",
    "#files_array_20=files_array_20_1+files_array_20_2\n",
    "print (files_array_20)\n",
    "print()\n",
    "print(\"Quantidade de arquivos do word no diretório: \",len(files_array_19))\n",
    "print(\"Quantidade de arquivos do word no diretório: \",len(files_array_20))\n",
    "\n",
    "\n",
    "\n",
    "# rodar método get_info para ler aquivos do Word e retornar features de cada arquivo\n",
    "# argumentos (diretório e array dos arquivos word)\n",
    "# retorna (NºID,Qtd_caracteres,Qtd_tabela,Qtd_image,data)\n",
    "\n",
    "var_19=gf.get_info(fileDir_19,files_array_19)\n",
    "var_20=gf.get_info(fileDir_20,files_array_20)\n",
    "\n",
    "#print(var)\n",
    "\n",
    "#Quantidade de arquivos do word no diretório:  58\n",
    "# Quantidade de arquivos do word no diretório:  52\n",
    "\n",
    "#Quantidade de arquivos do word no diretório:  56\n",
    "#Quantidade de arquivos do word no diretório:  50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#files_array_19_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Existe esse diretório?  True\n",
    "- Existe esse diretório?  True\n",
    "- Quantidade de arquivos do word no diretório:  58\n",
    "- Quantidade de arquivos do word no diretório:  35"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(var_19))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unindo lista 2019 com lista 2020\n",
    "var=var_19+var_20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df[df['Nº DA PLANILHA'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# converter veriável de retorno do método para Dataframe\n",
    "#df = pd.DataFrame(var,columns=['Nº DA PLANILHA',\"Qtd_carac\",\"Qtd_tabela\",\"Qtd_image\",\"Data\"])\n",
    "df = pd.DataFrame(var,columns=['Nº DA PLANILHA',\"Qtd_PG_word\",\"Qtd_carac\",\"Qtd_tabela\",\"Qtd_image\",\"Qtd_estilos\", \"Data\"])\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# verificando tipo das variáveis\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converter tipo para inteiros e data\n",
    "df[\"Nº DA PLANILHA\"] = pd.to_numeric(df[\"Nº DA PLANILHA\"], errors='coerce')\n",
    "df[\"Data\"] = pd.to_datetime(df[\"Data\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convertendo arquivo excel em dataframe\n",
    "\n",
    "excelDir =\"/Users/wpessoa/repositorios/Fluxo_Editorial/dados/\"\n",
    "excelFile_2019 = pd.read_excel(excelDir+'Exercicio_estimativa_de_paginas_2019_2020.xlsx',\"EXECUTADO 2019\")\n",
    "#excelFile_2020 = pd.read_excel(excelDir+'Exercicio_estimativa_de_paginas_2019_2020.xlsx',\"EXECUTADO 2020\")\n",
    "excelFile_2020 = pd.read_excel(excelDir+'Planilha de Acompanhamento Editoração 2020.xlsx',\"ACOMPANHAMENTO\", header=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(excelFile_2020.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(excelFile_2019.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "excelFile_2020.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "excelFile_2020.tail(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "excelFile_2019.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################################\n",
    "# FAZER MERGE COM excelFile_2020 & excelFile_2019\n",
    "##################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = [excelFile_2019, excelFile_2020]\n",
    "excelFile2 = pd.concat(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reindexar o index devido ter deletado algumas linhas\n",
    "excelFile2.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selecionando apenas colunas necessárias\n",
    "#colunas=['ENTIDADE','PUBLICAÇÃO','Nº de páginas WORD','Nº de páginas estimado', 'COMPLEXIDADE','FORNECEDOR','Nº DA PLANILHA','STATUS DE PGTO','Nº de páginas finais']\n",
    "colunas=['ENTIDADE', 'PUBLICAÇÃO', 'Nº de páginas WORD',\n",
    "       'Nº de páginas estimado', 'COMPLEXIDADE', 'FORNECEDOR',\n",
    "       'Nº DA PLANILHA', 'STATUS DE PGTO', 'Nº de páginas finais']\n",
    "\n",
    "excelFile2 = excelFile2[colunas]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "excelFile2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "excelFile2.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "excelFile2.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#excelFile2.set_index('Nº DA PLANILHA',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "excelFile2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "excelFile2.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar se tem alguma inconsistencia na planilha Excel - Quantidade de páginas por exemplo\n",
    "# excelFile2.sort_values('Nº de páginas WORD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "excelFile2['Nº de páginas finais'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar se tem alguma inconsistencia na planilha Excel - Quantidade de páginas por exemplo\n",
    "# excelFile2.sort_values('Nº de páginas finais')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# verifiacando valores nulos\n",
    "excelFile2.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retirar registro nulos\n",
    "excelFile2=excelFile2.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# verifiacando valores nulos\n",
    "excelFile2.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "excelFile2.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "excelFile2[\"Nº DA PLANILHA\"] = (pd.to_numeric(excelFile2[\"Nº DA PLANILHA\"], errors='coerce').fillna(0).astype(np.int64))#,downcast='integer'))\n",
    "#excelFile2[\"Nº DA PLANILHA\"] = excelFile2[\"Nº DA PLANILHA\"].astype('int64',errors='ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "excelFile2.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "excelFile2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# verificando quantidade de linhas\n",
    "df['Nº DA PLANILHA'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----> verificar valores NAN \n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# verificando quantidade de linhas com o coluna N0. da planilha igual a NaN\n",
    "df[df['Nº DA PLANILHA'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# verificando quantidade de linhas\n",
    "\n",
    "excelFile2['Nº DA PLANILHA'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----> verificar valores NAN \n",
    "excelFile2.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# verificando quantidade de linhas com o coluna N0. da planilha igual a NaN\n",
    "\n",
    "excelFile2[excelFile2['Nº DA PLANILHA'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UNIR arquivo do NGE com o método de leitura dos arquivos Word\n",
    "#\n",
    "# Atenção >>>>>>>> alguns arquivos não passaram pelo método de leitura dos arquivos word e irão gerar valores NAN\n",
    "#\n",
    "df_final = pd.merge(excelFile2, df, on=['Nº DA PLANILHA'], how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PRECISO REVISAR O MERGE, POIS A COLUNA DATA DO DATASET df NÃO FOI ENCORPORADO NO DATASET df_final "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# verificando quantidade de linhas\n",
    "\n",
    "df_final['Nº DA PLANILHA'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# colocando ordem de apresentação das colunas adequada\n",
    "excelFile2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# colocando ordem de apresentação das colunas adequada\n",
    "\n",
    "#colunas_final = ['Nº DA PLANILHA','ENTIDADE',  'FORNECEDOR','COMPLEXIDADE', 'STATUS DE PGTO',  'Nº de páginas WORD','Nº de páginas estimado', 'Qtd_carac','Qtd_tabela', 'Qtd_image','Nº de páginas finais' ]\n",
    "colunas_final = ['Nº DA PLANILHA','ENTIDADE',  'FORNECEDOR','COMPLEXIDADE', 'STATUS DE PGTO',  'Nº de páginas WORD','Nº de páginas estimado', \"Qtd_PG_word\", 'Qtd_carac','Qtd_tabela', 'Qtd_image',\"Qtd_estilos\",'Nº de páginas finais' ]\n",
    "df_final = df_final[colunas_final]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----> verificar valores NAN \n",
    "df_final.isnull().sum()\n",
    "# OS REGISTROS COM NAN NESSE CASO FORAM OS ARQUIVOS QUE ESTAVAM NO ARQUIVO EXCEL \n",
    "# E QUE NÃO TINHAM O AQUIVO WORD CORRESPONDENTE , OU SEJA NÃO FOI ENCONTRADO NA PASTA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final[df_final['Nº DA PLANILHA'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# lista dos arquivos do Excel que não tem arquivo do Word correspondente\n",
    "    \n",
    "    \n",
    "df_final[df_final['Qtd_carac'].isnull()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retirar registro nulos , OU SEJA RETIRAR OS DADOS QUE NÃO TINHAM NA PASTA DO WORD\n",
    "df_final=df_final.dropna()\n",
    "# APAGOU AS LINHAS COM NAN\n",
    "\n",
    "# outra alternativa seria preencher com valores as celulas com NaN \n",
    "# df_final.fillna(df_final.mean(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----> verificar valores NAN \n",
    "df_final.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(df_final[\"qtd_pag_word\"],(df_final[\"qtd_carc\"]/1430))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reindexar o index devido ter deletado algumas linhas\n",
    "df_final.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#colunas_final = ['Nº DA PLANILHA','ENTIDADE', 'PUBLICAÇÃO', 'FORNECEDOR','COMPLEXIDADE', 'STATUS DE PGTO', 'Data', 'Nº de páginas WORD', 'Nº de páginas estimado', 'Qtd_carac','Qtd_tabela', 'Qtd_image','Nº de páginas finais' ]\n",
    "#df_final_num = df_final[colunas_final]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_final.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alterar campos typo string para categóricos \n",
    "df_final['ENTIDADE'] = df_final['ENTIDADE'].astype('category')\n",
    "df_final['COMPLEXIDADE'] = df_final['COMPLEXIDADE'].astype('category')\n",
    "df_final['FORNECEDOR'] = df_final['FORNECEDOR'].astype('category')\n",
    "df_final['STATUS DE PGTO'] = df_final['STATUS DE PGTO'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOBRE O AVISO: A value is trying to be set on a copy of a slice from a dataframe\n",
    "# https://paulovasconcellos.com.br/o-que-%C3%A9-a-value-is-trying-to-be-set-on-a-copy-of-a-slice-from-a-dataframe-e85f744d8be1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alterar campos typo categóricos para numérico\n",
    "# aplicando .cat.codes em cada uma dessas colunas\n",
    "df_final['ENTIDADE'] = df_final['ENTIDADE'].cat.codes\n",
    "df_final['COMPLEXIDADE'] = df_final['COMPLEXIDADE'].cat.codes\n",
    "df_final['FORNECEDOR'] = df_final['FORNECEDOR'].cat.codes\n",
    "df_final['STATUS DE PGTO'] = df_final['STATUS DE PGTO'].cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final['Nº de páginas WORD'] = df_final['Nº de páginas WORD'].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar se tem alguma inconsistencia na planilha Excel - Quantidade de páginas por exemplo\n",
    "df_final.sort_values('Nº de páginas WORD')\n",
    "\n",
    "# eliminar linhas com menos de 10 páginas\n",
    "filtro  = df_final['Nº de páginas WORD'] > 10\n",
    "df_final = df_final[filtro]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trocar type float por int\n",
    "#df_final['Nº DA PLANILHA'] = df_final['Nº DA PLANILHA'].astype('int')\n",
    "#df_final['Nº DA PLANILHA'] = df_final['Nº DA PLANILHA'].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inserir zeros no lugar do valor NAN\n",
    "#df_final['Qtd_carac']= df_final['Qtd_carac'].fillna(0)\n",
    "#df_final['Qtd_tabela'] = df_final['Qtd_tabela'].fillna(0)\n",
    "#df_final['Qtd_image'] = df_final['Qtd_image'].fillna(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trocar type float por int\n",
    "#df_final['Nº de páginas estimado'] = df_final['Nº de páginas estimado'].astype('int')\n",
    "df_final['Qtd_carac'] = df_final['Qtd_carac'].astype('int')\n",
    "df_final[\"Qtd_PG_word\"] = df_final[\"Qtd_PG_word\"].astype('int')\n",
    "df_final['Qtd_tabela'] = df_final['Qtd_tabela'].astype('int')\n",
    "df_final['Qtd_image'] = df_final['Qtd_image'].astype('int')\n",
    "\n",
    "df_final['Nº de páginas finais'] = df_final['Nº de páginas finais'].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#renomear colunas\n",
    "#df_final.rename(columns={'Nº DA PLANILHA': 'id','ENTIDADE':\"entidade\",'FORNECEDOR':\"fornecedor\", 'COMPLEXIDADE':\"complexidade\",\n",
    "#                         'STATUS DE PGTO':\"stat_pagto\",'Nº de páginas WORD':\"qtd_pag_word\", \n",
    "#                         'Nº de páginas estimado':\"qtd_pag_estimado\", 'Qtd_carac':\"qtd_carc\",\n",
    "#       'Qtd_tabela':\"qtd_tabela\", 'Qtd_image': \"qtd_image\", 'Nº de páginas finais':\"pag_final\"} , inplace = True)\n",
    "\n",
    "df_final.rename(columns={'Nº DA PLANILHA': 'id','ENTIDADE':\"entidade\",'FORNECEDOR':\"fornecedor\", 'COMPLEXIDADE':\"complexidade\",\n",
    "                         'STATUS DE PGTO':\"stat_pagto\",'Nº de páginas WORD':\"qtd_pag_word\", \n",
    "                         'Nº de páginas estimado':\"qtd_pag_estimado\", 'Qtd_carac':\"qtd_carc\",\"Qtd_PG_word\":\"qtd_pg_word\",\n",
    "       'Qtd_tabela':\"qtd_tabela\", 'Qtd_image': \"qtd_image\",\"Qtd_estilos\":\"qtd_estilos\", 'Nº de páginas finais':\"pag_final\"} , inplace = True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(df_final[df_final[\"pag_final\"]>149]))\n",
    "print(len(df_final[(df_final[\"pag_final\"]>59) & (df_final[\"pag_final\"]<150)]))\n",
    "print(len(df_final[df_final[\"pag_final\"]<60]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final[df_final[\"pag_final\"]>120]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_final['tamanho_livro'] = 'NaN'\n",
    "for index, row in df_final.iterrows():\n",
    "    #print(row[\"pag_final\"])\n",
    "    if row[\"pag_final\"]>119:\n",
    "        df_final.loc[index,'tamanho_livro'] =  2\n",
    "    elif row[\"pag_final\"]>59 & row[\"pag_final\"]<120:\n",
    "        df_final.loc[index,'tamanho_livro'] =  1\n",
    "    else:  \n",
    "        df_final.loc[index,'tamanho_livro'] =  0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final[df_final['tamanho_livro']==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# gerar arquivo csv para arquivo tratado\n",
    "\n",
    "df_final.to_csv(\"nge_dados_input.csv\",index=False )\n",
    "\n",
    "#data = pd.read_csv(\"nge_dados_input.csv\")\n",
    "#df_final.to_csv(index=False)\n",
    "#df_final.to_csv(\"nge_dados_input.csv\", data = imprimir_ano)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIM MÉTODO..... RODADR O TRINEMANTO DE MACHINE LEARNING =>   machine_learning_NGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
