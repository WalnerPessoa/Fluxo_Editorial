{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Existe esse diretório?  True\n",
      "Quantidade de arquivos do word no diretório:  1\n",
      "Entre com o número da entidade: 1\n",
      "Entre com o número do fornecedor: 1\n",
      "Entre com o número de complexidade: 1\n",
      "Entre com o número de status de pagamento: 1\n",
      "Entre com o número de paginas Word: 1\n",
      "Entre com o número de pag_estimado: 1\n",
      "Entre com o número de pag_final 1\n",
      "Entre com o número de tamanho_livro: 1\n",
      "88\n",
      "111407\n",
      "37\n",
      "28\n",
      "60\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Object of type int64 is not JSON serializable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-7045aeee22cc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     82\u001b[0m }\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m \u001b[0mbody\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0murl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'https://ussouthcentral.services.azureml.net/workspaces/b61d12027ff74d329be4643248e190ae/services/f5b88ec8cfec45fa990be3d3e0b6ed71/execute?api-version=2.0&format=swagger'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py3/lib/python3.8/json/__init__.py\u001b[0m in \u001b[0;36mdumps\u001b[0;34m(obj, skipkeys, ensure_ascii, check_circular, allow_nan, cls, indent, separators, default, sort_keys, **kw)\u001b[0m\n\u001b[1;32m    229\u001b[0m         \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mindent\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mseparators\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m         default is None and not sort_keys and not kw):\n\u001b[0;32m--> 231\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_default_encoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    232\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m         \u001b[0mcls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mJSONEncoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py3/lib/python3.8/json/encoder.py\u001b[0m in \u001b[0;36mencode\u001b[0;34m(self, o)\u001b[0m\n\u001b[1;32m    197\u001b[0m         \u001b[0;31m# exceptions aren't as detailed.  The list call should be roughly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m         \u001b[0;31m# equivalent to the PySequence_Fast that ''.join() would do.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m         \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_one_shot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m             \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py3/lib/python3.8/json/encoder.py\u001b[0m in \u001b[0;36miterencode\u001b[0;34m(self, o, _one_shot)\u001b[0m\n\u001b[1;32m    255\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkey_separator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem_separator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_keys\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m                 self.skipkeys, _one_shot)\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_iterencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m def _make_iterencode(markers, _default, _encoder, _indent, _floatstr,\n",
      "\u001b[0;32m~/miniconda3/envs/py3/lib/python3.8/json/encoder.py\u001b[0m in \u001b[0;36mdefault\u001b[0;34m(self, o)\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m         \"\"\"\n\u001b[0;32m--> 179\u001b[0;31m         raise TypeError(f'Object of type {o.__class__.__name__} '\n\u001b[0m\u001b[1;32m    180\u001b[0m                         f'is not JSON serializable')\n\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Object of type int64 is not JSON serializable"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import urllib.request\n",
    "import json\n",
    "import get_file_word as gf\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "fileExt_input = r\".docx\"\n",
    "fileDir_input = r\"/Users/wpessoa/repositorios/NGE/input/\"\n",
    "print(\"Existe esse diretório? \",os.path.exists(fileDir_input)) \n",
    "\n",
    "files_array_input = [_ for _ in os.listdir(fileDir_input) if _.endswith(fileExt_input)]\n",
    "\n",
    "print(\"Quantidade de arquivos do word no diretório: \",len(files_array_input))\n",
    "var__input=gf.get_info(fileDir_input,files_array_input)\n",
    "\n",
    "\n",
    "#campo1 = input('Entre com o número de id: ')\n",
    "campo2 = input('Entre com o número da entidade: ')\n",
    "campo3 = input('Entre com o número do fornecedor: ')\n",
    "campo4 = input('Entre com o número de complexidade: ')\n",
    "campo5 = input('Entre com o número de status de pagamento: ')\n",
    "campo6 = input('Entre com o número de paginas Word: ')\n",
    "campo7 = input('Entre com o número de pag_estimado: ')\n",
    "campo8 = input('Entre com o número de pag_final ')\n",
    "campo9 = input('Entre com o número de tamanho_livro: ')\n",
    "\n",
    "df = pd.DataFrame(var__input,columns=['num_id',\"qtd_pg_word\",\"qtd_carac\",\"qtd_tabela\",\"qtd_image\",\"qtd_estilos\", \"Data\"])\n",
    "print(df[\"qtd_pg_word\"][0])\n",
    "print(df[\"qtd_carac\"][0])\n",
    "print(df[\"qtd_tabela\"][0])\n",
    "print(df[\"qtd_image\"][0])\n",
    "print(df[\"qtd_estilos\"][0])\n",
    "campoA = df[\"qtd_pg_word\"][0]\n",
    "campoB = df[\"qtd_carac\"][0]\n",
    "campoC = df[\"qtd_tabela\"][0]\n",
    "campoD = df[\"qtd_image\"][0]\n",
    "campoE = df[\"qtd_estilos\"][0]\n",
    "\n",
    "\n",
    "\n",
    "data = {\n",
    "        \"Inputs\": {\n",
    "                \"input1\":\n",
    "                [\n",
    "                    {\n",
    "                            'id': df[\"num_id\"][0],   \n",
    "                            'entidade': campo2,   \n",
    "                            'fornecedor': campo3,   \n",
    "                            'complexidade': campo4,   \n",
    "                            'stat_pagto': campo5,   \n",
    "                            'qtd_pag_word': campo6,   \n",
    "                            'qtd_pag_estimado': campo7,   \n",
    "                            'qtd_pg_word': campoA,   \n",
    "                            'qtd_carc': campoB,   \n",
    "                            'qtd_tabela': campoC,   \n",
    "                            'qtd_image': campoD,   \n",
    "                            'qtd_estilos': campoE,   \n",
    "                            'pag_final': campo8,   \n",
    "                            'tamanho_livro': campo9,   \n",
    "                    }\n",
    "                    #{\n",
    "                    #        'id': \"224323\",   \n",
    "                    #       'entidade': \"0\",   \n",
    "                    #        'fornecedor': \"0\",   \n",
    "                    #        'complexidade': \"1\",   \n",
    "                    #        'stat_pagto': \"1\",   \n",
    "                    #        'qtd_pag_word': \"87\",   \n",
    "                    #        'qtd_pag_estimado': \"140\",   \n",
    "                    #        'qtd_pg_word': \"87\",   \n",
    "                    #        'qtd_carc': \"116142\",   \n",
    "                    #        'qtd_tabela': \"505\",   \n",
    "                    #        'qtd_image': \"742\",   \n",
    "                    #        'qtd_estilos': \"60\",   \n",
    "                    #        'pag_final': \"140\",   \n",
    "                    #        'tamanho_livro': \"2\",   \n",
    "                    #}\n",
    "                ],\n",
    "        },\n",
    "    \"GlobalParameters\":  {\n",
    "    }\n",
    "}\n",
    "\n",
    "body = str.encode(json.dumps(data))\n",
    "\n",
    "url = 'https://ussouthcentral.services.azureml.net/workspaces/b61d12027ff74d329be4643248e190ae/services/f5b88ec8cfec45fa990be3d3e0b6ed71/execute?api-version=2.0&format=swagger'\n",
    "api_key = 'pQgdJMkoqXg865xYDZPpDhxu1BJUupNSpSDThyM/iyUOvOtLa2QwvFLNdoNUH0kfucNxfqkTcHBOfb7eDPzaUw==' # Replace this with the API key for the web service\n",
    "headers = {'Content-Type':'application/json', 'Authorization':('Bearer '+ api_key)}\n",
    "\n",
    "req = urllib.request.Request(url, body, headers)\n",
    "\n",
    "try:\n",
    "    response = urllib.request.urlopen(req)\n",
    "\n",
    "    result = response.read()\n",
    "    print(result)\n",
    "except urllib.error.HTTPError as error:\n",
    "    print(\"The request failed with status code: \" + str(error.code))\n",
    "\n",
    "    # Print the headers - they include the requert ID and the timestamp, which are useful for debugging the failure\n",
    "    print(error.info())\n",
    "    print(json.loads(error.read().decode(\"utf8\", 'ignore')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
