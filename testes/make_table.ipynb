{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# metodo de tratar tabelas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Existe esse diretório?  True\n",
      "Existe esse diretório?  True\n",
      "Quantidade de arquivos do word no diretório:  58\n",
      "Quantidade de arquivos do word no diretório:  35\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import get_file_word as gf\n",
    "import datetime\n",
    "import pandas as pd\n",
    "\n",
    "#setar variáveis onde estão arquivos\n",
    "fileExt = r\".docx\"\n",
    "fileExt2 = r\".doc\"\n",
    "fileDir_19 = r\"/Users/wpessoa/repositorios/NGE/words_2019/\"\n",
    "fileDir_20 = r\"/Users/wpessoa/repositorios/NGE/words_2020/\"\n",
    "\n",
    "\n",
    "# verificar se existe o diretório\n",
    "print(\"Existe esse diretório? \",os.path.exists(fileDir_19)) \n",
    "print(\"Existe esse diretório? \",os.path.exists(fileDir_20)) \n",
    "\n",
    "\n",
    "#fileDir = r\"/Users/wpessoa/repositorios/Fluxo_Editorial/words/\"\n",
    "#fileDir= r'/Users/walnerpessoa/repositories/Fluxo_Editorial/words'\n",
    "files_array_19 = [_ for _ in os.listdir(fileDir_19) if _.endswith(fileExt)]\n",
    "#files_array_19_2 = [_ for _ in os.listdir(fileDir_19) if _.endswith(fileExt2)]\n",
    "#files_array_19=files_array_19_1+files_array_19_2\n",
    "\n",
    "\n",
    "files_array_20 = [_ for _ in os.listdir(fileDir_20) if _.endswith(fileExt)]\n",
    "#files_array_20_2 = [_ for _ in os.listdir(fileDir_20) if _.endswith(fileExt2)]\n",
    "#files_array_20=files_array_20_1+files_array_20_2\n",
    "\n",
    "print(\"Quantidade de arquivos do word no diretório: \",len(files_array_19))\n",
    "print(\"Quantidade de arquivos do word no diretório: \",len(files_array_20))\n",
    "\n",
    "\n",
    "# rodar método get_info para ler aquivos do Word e retornar features de cada arquivo\n",
    "# argumentos (diretório e array dos arquivos word)\n",
    "# retorna (NºID,Qtd_caracteres,Qtd_tabela,Qtd_image,data)\n",
    "\n",
    "var_19=gf.get_info(fileDir_19,files_array_19)\n",
    "var_20=gf.get_info(fileDir_20,files_array_20)\n",
    "\n",
    "#print(var)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'win32com'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-a3f2a9dfa557>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mwin32com\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mwin32\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mwin32com\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconstants\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'win32com'"
     ]
    }
   ],
   "source": [
    "#\n",
    "#\n",
    "# converter arquivo DOC para arquivo DOCX\n",
    "#\n",
    "#\n",
    "\n",
    "# https://stackoverflow.com/questions/38468442/multiple-doc-to-docx-file-conversion-using-python\n",
    "from glob import glob\n",
    "import re\n",
    "import os\n",
    "import win32com.client as win32\n",
    "from win32com.client import constants\n",
    "\n",
    "# Create list of paths to .doc files\n",
    "paths = glob('C:\\\\path\\\\to\\\\doc\\\\files\\\\**\\\\*.doc', recursive=True)\n",
    "\n",
    "def save_as_docx(path):\n",
    "    # Opening MS Word\n",
    "    word = win32.gencache.EnsureDispatch('Word.Application')\n",
    "    doc = word.Documents.Open(path)\n",
    "    doc.Activate ()\n",
    "\n",
    "    # Rename path with .docx\n",
    "    new_file_abs = os.path.abspath(path)\n",
    "    new_file_abs = re.sub(r'\\.\\w+$', '.docx', new_file_abs)\n",
    "\n",
    "    # Save and Close\n",
    "    word.ActiveDocument.SaveAs(\n",
    "        new_file_abs, FileFormat=constants.wdFormatXMLDocument\n",
    "    )\n",
    "    doc.Close(False)\n",
    "\n",
    "for path in paths:\n",
    "    save_as_docx(files_array_19_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ID227130-2019-01-18_Guia de Financiamento Climático_vs final (2).doc',\n",
       " 'ID000000-Manual de formatos - Oficial.doc',\n",
       " 'ID232393-Guia Avaliação última versão v 02_10_2019 _ Normalizado (1).doc']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files_array_19_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Existe esse diretório?  True\n",
    "- Existe esse diretório?  True\n",
    "- Quantidade de arquivos do word no diretório:  58\n",
    "- Quantidade de arquivos do word no diretório:  35"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(var_19))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unindo lista 2019 com lista 2020\n",
    "var=var_19+var_20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converter veriável de retorno do método para Dataframe\n",
    "df = pd.DataFrame(var,columns=['Nº DA PLANILHA',\"Qtd_carac\",\"Qtd_tabela\",\"Qtd_image\",\"Data\"])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# verificando tipo das variáveis\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converter tipo para inteiros e data\n",
    "df[\"Nº DA PLANILHA\"] = pd.to_numeric(df[\"Nº DA PLANILHA\"], errors='coerce')\n",
    "df[\"Data\"] = pd.to_datetime(df[\"Data\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convertendo arquivo excel em dataframe\n",
    "\n",
    "excelDir =\"/Users/wpessoa/repositorios/Fluxo_Editorial/dados/\"\n",
    "excelFile_2019 = pd.read_excel(excelDir+'Exercicio_estimativa_de_paginas_2019_2020.xlsx',\"EXECUTADO 2019\")\n",
    "excelFile_2020 = pd.read_excel(excelDir+'Exercicio_estimativa_de_paginas_2019_2020.xlsx',\"EXECUTADO 2020\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(excelFile_2020.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(excelFile_2019.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################################\n",
    "# FAZER MERGE COM excelFile_2020 & excelFile_2019\n",
    "##################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = [excelFile_2019, excelFile_2020]\n",
    "excelFile2 = pd.concat(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reindexar o index devido ter deletado algumas linhas\n",
    "excelFile2.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selecionando apenas colunas necessárias\n",
    "colunas=['ENTIDADE','PUBLICAÇÃO','Nº de páginas WORD','Nº de páginas estimado', 'COMPLEXIDADE','FORNECEDOR','Nº DA PLANILHA','STATUS DE PGTO','Nº de páginas finais']\n",
    "excelFile2 = excelFile2[colunas]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "excelFile2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "excelFile2.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "excelFile2.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#excelFile2.set_index('Nº DA PLANILHA',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "excelFile2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# verifiacando valores nulos\n",
    "excelFile2.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retirar registro nulos\n",
    "excelFile2=excelFile2.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# verifiacando valores nulos\n",
    "excelFile2.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "excelFile2.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "excelFile2[\"Nº DA PLANILHA\"] = (pd.to_numeric(excelFile2[\"Nº DA PLANILHA\"], errors='coerce').fillna(0).astype(np.int64))#,downcast='integer'))\n",
    "#excelFile2[\"Nº DA PLANILHA\"] = excelFile2[\"Nº DA PLANILHA\"].astype('int64',errors='ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "excelFile2.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "excelFile2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unir arquivo do NGE com o método de leitura dos arquivos Word\n",
    "#\n",
    "# Atenção >>>>>>>> alguns arquivos não passaram pelo método de leitura dos arquivos word e irão gerar valores NAN\n",
    "#\n",
    "df_final = pd.merge(excelFile2, df, on=['Nº DA PLANILHA'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# colocando ordem das colunas adequada\n",
    "excelFile2.columns\n",
    "colunas_final = ['Nº DA PLANILHA','ENTIDADE',  'FORNECEDOR','COMPLEXIDADE', 'STATUS DE PGTO',  'Nº de páginas WORD','Nº de páginas estimado', 'Qtd_carac','Qtd_tabela', 'Qtd_image','Nº de páginas finais' ]\n",
    "\n",
    "df_final = df_final[colunas_final]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----> verificar valores NAN \n",
    "df_final.isnull().sum()\n",
    "# OS REGISTROS COM NAN NESSE CASO FORAM OS ARQUIVOS WORD QUE NÃO FOI ENCONTRADO."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retirar registro nulos\n",
    "df_final=df_final.dropna()\n",
    "# APAGOU AS LINHAS COM NAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----> verificar valores NAN \n",
    "df_final.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reindexar o index devido ter deletado algumas linhas\n",
    "df_final.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#colunas_final = ['Nº DA PLANILHA','ENTIDADE', 'PUBLICAÇÃO', 'FORNECEDOR','COMPLEXIDADE', 'STATUS DE PGTO', 'Data', 'Nº de páginas WORD', 'Nº de páginas estimado', 'Qtd_carac','Qtd_tabela', 'Qtd_image','Nº de páginas finais' ]\n",
    "#df_final_num = df_final[colunas_final]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_final.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alterar campos typo string para categóricos \n",
    "df_final['ENTIDADE'] = df_final['ENTIDADE'].astype('category')\n",
    "df_final['COMPLEXIDADE'] = df_final['COMPLEXIDADE'].astype('category')\n",
    "df_final['FORNECEDOR'] = df_final['FORNECEDOR'].astype('category')\n",
    "df_final['STATUS DE PGTO'] = df_final['STATUS DE PGTO'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOBRE O AVISO: A value is trying to be set on a copy of a slice from a dataframe\n",
    "# https://paulovasconcellos.com.br/o-que-%C3%A9-a-value-is-trying-to-be-set-on-a-copy-of-a-slice-from-a-dataframe-e85f744d8be1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alterar campos typo categóricos para numérico\n",
    "# aplicando .cat.codes em cada uma dessas colunas\n",
    "df_final['ENTIDADE'] = df_final['ENTIDADE'].cat.codes\n",
    "df_final['COMPLEXIDADE'] = df_final['COMPLEXIDADE'].cat.codes\n",
    "df_final['FORNECEDOR'] = df_final['FORNECEDOR'].cat.codes\n",
    "df_final['STATUS DE PGTO'] = df_final['STATUS DE PGTO'].cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final['Nº de páginas WORD'] = df_final['Nº de páginas WORD'].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trocar type float por int\n",
    "#df_final['Nº DA PLANILHA'] = df_final['Nº DA PLANILHA'].astype('int')\n",
    "#df_final['Nº DA PLANILHA'] = df_final['Nº DA PLANILHA'].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inserir zeros no lugar do valor NAN\n",
    "#df_final['Qtd_carac']= df_final['Qtd_carac'].fillna(0)\n",
    "#df_final['Qtd_tabela'] = df_final['Qtd_tabela'].fillna(0)\n",
    "#df_final['Qtd_image'] = df_final['Qtd_image'].fillna(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trocar type float por int\n",
    "#df_final['Nº de páginas estimado'] = df_final['Nº de páginas estimado'].astype('int')\n",
    "df_final['Qtd_carac'] = df_final['Qtd_carac'].astype('int')\n",
    "df_final['Qtd_tabela'] = df_final['Qtd_tabela'].astype('int')\n",
    "df_final['Qtd_image'] = df_final['Qtd_image'].astype('int')\n",
    "\n",
    "df_final['Nº de páginas finais'] = df_final['Nº de páginas finais'].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#renomear colunas\n",
    "df_final.rename(columns={'Nº DA PLANILHA': 'id','ENTIDADE':\"entidade\",'FORNECEDOR':\"fornecedor\", 'COMPLEXIDADE':\"complexidade\",\n",
    "                         'STATUS DE PGTO':\"stat_pagto\",'Nº de páginas WORD':\"qtd_pag_word\", \n",
    "                         'Nº de páginas estimado':\"qtd_pag_estimado\", 'Qtd_carac':\"qtd_carc\",\n",
    "       'Qtd_tabela':\"qtd_tabela\", 'Qtd_image': \"qtd_image\", 'Nº de páginas finais':\"pag_final\"} , inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# gerar arquivo csv para arquivo tratado\n",
    "\n",
    "df_final.to_csv(\"nge_dados_input.csv\",index=False )\n",
    "\n",
    "#data = pd.read_csv(\"nge_dados_input.csv\")\n",
    "#df_final.to_csv(index=False)\n",
    "#df_final.to_csv(\"nge_dados_input.csv\", data = imprimir_ano)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
